{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0b0fd5-9693-4e71-8246-a2d04c3cea77",
   "metadata": {},
   "source": [
    "## Effect of Matrix Transformations on data with Standard Algorithms Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc861576-23c3-457e-9a10-5b019689feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
    "\n",
    "# Ignore the FutureWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Ignore the ConvergenceWarning and UserWarning\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac68afd5-ea27-430c-9999-9b9fb06d9504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe visualization: \n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "url = \"https://drive.google.com/file/d/16YkA1qJ4FHcBIvXZc17ifKSUzb_Xihth/view?usp=sharing\"\n",
    "url = \"https://drive.google.com/uc?id=\" + url.split('/')[-2]\n",
    "\n",
    "# Dataset visualization as DataFrame\n",
    "dataset = pd.read_csv(url, header = 0)\n",
    "print(\"Dataframe visualization: \")\n",
    "dataset\n",
    "\n",
    "seed_new = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74302440-b58b-48cc-8a60-15b586faaa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Indices (Descending Sorted):\n",
      "['116' '142' '31' ... '604' '613' '614']\n"
     ]
    }
   ],
   "source": [
    "def calculate_relevance_array(dataset):\n",
    "    # Assuming the last column contains the class labels\n",
    "    classes = dataset.iloc[:, -1].unique()\n",
    "\n",
    "    # Create an empty DataFrame to store the mean per class\n",
    "    mean_per_class_df = pd.DataFrame(index=classes, columns=dataset.columns[: -1])\n",
    "\n",
    "    # Calculate mean for each feature per class\n",
    "    for class_label in classes:\n",
    "        class_data = dataset[dataset.iloc[:, -1] == class_label].iloc[:, :-1]\n",
    "        mean_per_class_df.loc[class_label] = class_data.mean()\n",
    "\n",
    "    # Calculate the difference between the mean of Class 0 and Class 1\n",
    "    mean_difference = mean_per_class_df.loc[classes[0]] - mean_per_class_df.loc[classes[1]]\n",
    "    # Sort the array in descending order and extract the indices\n",
    "    relevance_indices = mean_difference.sort_values(ascending = False).index.to_numpy()\n",
    "\n",
    "    # Sort the array in descending order\n",
    "    relevance_array = mean_difference.sort_values(ascending = False)\n",
    "\n",
    "    return relevance_array, relevance_indices\n",
    "\n",
    "relevance_array, relevance_indices = calculate_relevance_array(dataset)\n",
    "\n",
    "print(\"Relevance Indices (Descending Sorted):\")\n",
    "print(relevance_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137d1ec-103c-415a-a404-05ae95192543",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a4095b-dce7-4938-a644-3cf0f6d3a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8666666666666666\n",
      "Corresponding Relevance Indices: ['116', '142']\n",
      "Number of Relevance Features:  2\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.71      0.83        14\n",
      "     Clase 1       0.78      1.00      0.88        14\n",
      "\n",
      "    accuracy                           0.86        28\n",
      "   macro avg       0.89      0.86      0.85        28\n",
      "weighted avg       0.89      0.86      0.85        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_classifier_with_kfcv(dataset, k_neighbors, num_folds, relevance_indices, output_file):\n",
    "    # Assuming the last column contains the class labels\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]\n",
    "\n",
    "    # Initialize kNN classifier\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors = k_neighbors)\n",
    "\n",
    "    # Initialize k-Fold Cross-Validation\n",
    "    kf = KFold(n_splits = num_folds, shuffle = True, random_state = seed_new)\n",
    "\n",
    "    # Results dictionary to store metrics for each iteration\n",
    "    results = {'Accuracy': [], 'Relevance_Indices': []}\n",
    "    # Initialize an empty list to accumulate indices\n",
    "    accumulated_indices = []\n",
    "    \n",
    "    # Initialize variables to keep track of the best accuracy and its corresponding indices\n",
    "    best_accuracy = 0.0\n",
    "    best_relevance_indices = None\n",
    "    best_classification_report = None\n",
    "\n",
    "    # Iterate through relevance indices\n",
    "    for feature_index in relevance_indices:\n",
    "        # Initialize lists to store metrics for each fold\n",
    "        accuracy_list = []\n",
    "\n",
    "        # Lists to store the predicted and actual labels\n",
    "        predicted_labels = []\n",
    "        actual_labels = []\n",
    "\n",
    "        # Iterate through each fold\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Add one feature at a time based on relevance indices\n",
    "            X_train_current = X_train.iloc[:, : int(feature_index) + 1]\n",
    "            X_test_current = X_test.iloc[:, : int(feature_index) + 1]\n",
    "            \n",
    "            # Fit kNN classifier\n",
    "            knn_classifier.fit(X_train_current, y_train)\n",
    "            # Predict on test set\n",
    "            y_pred = knn_classifier.predict(X_test_current)\n",
    "            predicted_labels.extend(y_pred)\n",
    "            actual_labels.extend(y_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # Append accuracy to the list\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        # Calculate mean accuracy\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "        # Append mean accuracy and accumulated relevance indices for each feature to results dictionary\n",
    "        results['Accuracy'].append(mean_accuracy)\n",
    "        accumulated_indices.append(feature_index)\n",
    "        results['Relevance_Indices'].append(accumulated_indices.copy())\n",
    "\n",
    "        # Update the best accuracy and its corresponding indices\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_relevance_indices = accumulated_indices.copy()\n",
    "\n",
    "            # Calculate the best classification report\n",
    "            labels = ['Clase 0', 'Clase 1']\n",
    "            best_classification_report = classification_report(actual_labels, predicted_labels, target_names=labels)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    results['Accuracy'] = np.array(results['Accuracy'])\n",
    "    results['Relevance_Indices'] = np.array(results['Relevance_Indices'], dtype=object)\n",
    "\n",
    "    # Sort the accuracies and their corresponding indices in ascending order\n",
    "    sorted_indices = np.argsort(results['Accuracy'])\n",
    "    results['Accuracy'] = results['Accuracy'][sorted_indices]\n",
    "    results['Relevance_Indices'] = results['Relevance_Indices'][sorted_indices]\n",
    "\n",
    "    # Print the best accuracy and its corresponding indices\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Corresponding Relevance Indices: {best_relevance_indices}\")\n",
    "    print(\"Number of Relevance Features: \", len(best_relevance_indices))\n",
    "    \n",
    "    # Print the best classification report\n",
    "    print(\"Best Classification Report:\")\n",
    "    print(best_classification_report)\n",
    "\n",
    "    # Save the best classification report to a file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Best Classification Report:\\n\")\n",
    "        file.write(best_classification_report)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run kNN classifier with kFCV and save the best classification report to a file\n",
    "results = knn_classifier_with_kfcv(dataset, k_neighbors = 1, num_folds = 10, relevance_indices = relevance_indices, output_file = 'best_classification_report_1nn.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43dc1d6-957e-43d8-a600-67ae8aa6d2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7666666666666666\n",
      "Corresponding Relevance Indices: ['116', '142', '31', '132']\n",
      "Number of Relevance Features:  4\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.57      0.73        14\n",
      "     Clase 1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.85      0.79      0.78        28\n",
      "weighted avg       0.85      0.79      0.78        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run kNN classifier with kFCV and save the best classification report to a file\n",
    "results = knn_classifier_with_kfcv(dataset, k_neighbors = 3, num_folds = 10, relevance_indices = relevance_indices, output_file = 'best_classification_report_3nn.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a88fa46-5a0b-4095-abd8-956bd9367893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7666666666666666\n",
      "Corresponding Relevance Indices: ['116', '142', '31', '132', '1048', '734', '695', '837', '125', '70', '867', '240', '563', '147', '323', '479', '968', '124', '505', '334', '966', '773', '777', '191', '146', '916', '227', '471', '765', '735', '609', '503', '98', '757', '118', '504', '969', '825', '336', '223', '183', '509', '980', '351', '936', '673', '544', '467', '422', '664', '1010', '829', '545', '115', '35', '705', '912', '270', '758', '547', '709', '748', '1', '586', '508', '1030', '610', '808', '8', '1003', '264', '538', '583', '533', '300', '863', '974', '247', '929', '458', '287', '760', '917', '76', '970', '790', '913', '216', '445', '921', '779', '726', '314', '740', '820', '636', '712', '350', '66', '356', '600', '129', '4', '1063', '535', '697', '301', '156', '906', '510', '501', '202', '792', '891', '603', '439', '74', '332', '631', '180', '1037', '396', '878', '10', '160', '490', '985', '597', '395', '536', '228', '596', '710', '1056', '34', '121', '474', '244', '531', '821', '997', '720', '918', '55', '119', '585', '774', '162', '271', '1027', '810', '464', '653', '431', '486', '967', '493', '318', '942', '534', '200', '218', '64', '284', '241', '79', '934', '756', '296', '377', '285', '819', '656', '607', '973', '884', '541', '489', '186', '548', '693', '420', '633', '1044', '1043', '322', '574', '573', '199', '401', '130', '608', '590', '945', '1014', '612', '928', '539', '268', '796', '782', '317', '963', '1061', '139', '128', '75', '737', '85', '341', '365', '824', '696', '137', '983', '670', '57', '976', '998', '344', '48', '908', '369', '957', '715', '926', '1020', '363', '659', '259', '951', '798', '835', '683', '822', '195', '561', '320', '295', '528', '2', '502', '298', '477', '944', '546', '325', '565', '1039', '63', '850', '1022', '977', '635', '21', '362', '860', '151', '229', '107', '992', '1019', '702', '222', '374', '699', '623', '5', '164', '30', '174', '718', '764', '61', '778', '1032', '812', '959', '328', '6', '488', '769', '452', '830', '391', '305', '743', '108', '117', '261', '226', '402', '930', '447', '72', '100', '457', '755', '595', '622', '762', '321', '681', '719', '655', '179', '887', '995', '297', '110', '39', '828', '843', '415', '724', '113', '220', '78', '319', '814', '1012', '582', '215', '311', '238', '813', '143', '752', '1055', '403', '436', '171', '638', '986', '197', '304', '429', '122', '428', '1065', '703', '644', '628', '960', '444', '94', '579', '478', '588', '157', '416', '566', '245', '591', '708', '975', '248', '946', '273', '144', '874', '753', '564', '67', '262', '686', '360', '266', '1002', '95', '92', '889', '972', '33', '476', '562', '620', '497', '232', '587', '660', '303', '459', '629', '988', '73', '324', '569', '669', '278', '185', '1001', '134', '940', '104', '979', '750', '56', '739', '99', '783', '43', '892', '763', '102', '550', '290', '348', '676', '154', '679', '713', '643', '406', '213', '90', '443', '383', '400', '1000', '225', '84', '592', '176', '16', '768', '525', '1060', '518', '349', '326', '795', '291', '103', '747', '862', '189', '456', '249', '738', '177', '315', '646', '282', '161', '514', '382', '500', '800', '602', '909', '58', '512', '399', '858', '1016', '495', '572', '81', '730', '685', '593', '1049', '581', '875', '242', '460', '526', '52', '625', '260', '306', '390', '1047', '950', '1004', '894', '1023', '410', '932', '453', '626', '770', '407', '22', '780', '243', '864', '1013', '903', '484', '507', '1066', '847', '589', '939', '577', '722', '353', '368', '721', '378', '302', '414', '82', '385', '27', '28', '178', '869', '706', '308', '254', '209', '855', '791', '221', '665', '1064', '492', '173', '187', '210', '384', '425', '861', '283', '392', '1008', '380', '127', '827', '978', '789', '126', '12', '80', '470', '728', '310', '1011', '520', '859', '1070', '462', '330', '18', '714', '366', '922', '418', '772', '153', '784', '842', '405', '190', '54']\n",
      "Number of Relevance Features:  558\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.57      0.73        14\n",
      "     Clase 1       0.70      1.00      0.82        14\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.85      0.79      0.78        28\n",
      "weighted avg       0.85      0.79      0.78        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run kNN classifier with kFCV and save the best classification report to a file\n",
    "results = knn_classifier_with_kfcv(dataset, k_neighbors = 5, num_folds = 10, relevance_indices = relevance_indices, output_file = 'best_classification_report_5nn.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f772b-a7a0-4592-bd7c-c13dcf8e01a7",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805f56ca-a542-441c-ab3e-1af1d62b84d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 1.0\n",
      "Corresponding Relevance Indices: ['116', '142', '31', '132', '1048', '734', '695', '837', '125', '70', '867', '240', '563', '147', '323']\n",
      "Number of Relevance Features:  15\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00        14\n",
      "     Clase 1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_classifier_with_kfcv(dataset, relevance_indices, num_folds, output_file):\n",
    "    # Assuming the last column contains the class labels\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]\n",
    "\n",
    "    # Initialize SVM classifier\n",
    "    svm_classifier = SVC()\n",
    "\n",
    "    # Initialize k-Fold Cross-Validation\n",
    "    kf = KFold(n_splits = num_folds, shuffle = True, random_state = seed_new)\n",
    "\n",
    "    # Results dictionary to store metrics for each iteration\n",
    "    results = {'Accuracy': [], 'Relevance_Indices': []}\n",
    "    # Initialize an empty list to accumulate indices\n",
    "    accumulated_indices = []\n",
    "    \n",
    "    # Initialize variables to keep track of the best accuracy and its corresponding indices\n",
    "    best_accuracy = 0.0\n",
    "    best_relevance_indices = None\n",
    "    best_classification_report = None\n",
    "\n",
    "    # Iterate through relevance indices\n",
    "    for feature_index in relevance_indices:\n",
    "        # Initialize lists to store metrics for each fold\n",
    "        accuracy_list = []\n",
    "\n",
    "        # Lists to store the predicted and actual labels\n",
    "        predicted_labels = []\n",
    "        actual_labels = []\n",
    "\n",
    "        # Iterate through each fold\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Add one feature at a time based on relevance indices\n",
    "            X_train_current = X_train.iloc[:, : int(feature_index) + 1]\n",
    "            X_test_current = X_test.iloc[:, : int(feature_index) + 1]\n",
    "            \n",
    "            # Fit SVM classifier\n",
    "            svm_classifier.fit(X_train_current, y_train)\n",
    "            # Predict on test set\n",
    "            y_pred = svm_classifier.predict(X_test_current)\n",
    "            predicted_labels.extend(y_pred)\n",
    "            actual_labels.extend(y_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # Append accuracy to the list\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        # Calculate mean accuracy\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "        # Append mean accuracy and accumulated relevance indices for each feature to results dictionary\n",
    "        results['Accuracy'].append(mean_accuracy)\n",
    "        accumulated_indices.append(feature_index)\n",
    "        results['Relevance_Indices'].append(accumulated_indices.copy())\n",
    "\n",
    "        # Update the best accuracy and its corresponding indices\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_relevance_indices = accumulated_indices.copy()\n",
    "\n",
    "            # Calculate the best classification report\n",
    "            labels = ['Clase 0', 'Clase 1']\n",
    "            best_classification_report = classification_report(actual_labels, predicted_labels, target_names=labels)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    results['Accuracy'] = np.array(results['Accuracy'])\n",
    "    results['Relevance_Indices'] = np.array(results['Relevance_Indices'], dtype=object)\n",
    "\n",
    "    # Sort the accuracies and their corresponding indices in ascending order\n",
    "    sorted_indices = np.argsort(results['Accuracy'])\n",
    "    results['Accuracy'] = results['Accuracy'][sorted_indices]\n",
    "    results['Relevance_Indices'] = results['Relevance_Indices'][sorted_indices]\n",
    "\n",
    "    # Print the best accuracy and its corresponding indices\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Corresponding Relevance Indices: {best_relevance_indices}\")\n",
    "    print(\"Number of Relevance Features: \", len(best_relevance_indices))\n",
    "    \n",
    "    # Print the best classification report\n",
    "    print(\"Best Classification Report:\")\n",
    "    print(best_classification_report)\n",
    "\n",
    "    # Save the best classification report to a file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Best Classification Report:\\n\")\n",
    "        file.write(best_classification_report)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run kNN classifier with kFCV and save the best classification report to a file\n",
    "results = svm_classifier_with_kfcv(dataset, num_folds = 10, relevance_indices = relevance_indices, output_file = 'best_classification_report_svm.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f70a1b-8a3a-461e-a25f-7e80b25467e5",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd625404-6db0-4183-ad15-810cbce827ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9666666666666666\n",
      "Corresponding Relevance Indices: ['116', '142', '31', '132', '1048', '734', '695', '837', '125', '70', '867', '240', '563', '147', '323', '479', '968', '124', '505', '334', '966', '773', '777', '191', '146', '916', '227', '471', '765', '735', '609', '503', '98', '757', '118', '504', '969', '825', '336', '223', '183', '509', '980', '351', '936', '673', '544', '467', '422', '664', '1010', '829', '545', '115', '35', '705', '912', '270', '758', '547', '709', '748', '1', '586', '508', '1030', '610', '808', '8', '1003', '264', '538', '583', '533', '300', '863', '974', '247', '929', '458', '287', '760', '917', '76', '970', '790', '913', '216', '445', '921', '779', '726', '314', '740', '820', '636', '712', '350', '66', '356', '600', '129', '4', '1063', '535', '697', '301', '156', '906', '510', '501', '202', '792', '891', '603', '439', '74', '332', '631', '180', '1037', '396', '878', '10', '160', '490', '985', '597', '395', '536', '228', '596', '710', '1056', '34', '121', '474', '244', '531', '821', '997', '720', '918', '55', '119', '585', '774', '162', '271', '1027', '810', '464', '653', '431', '486', '967', '493', '318', '942', '534', '200', '218', '64', '284', '241', '79', '934', '756', '296', '377', '285', '819', '656', '607', '973', '884', '541', '489', '186', '548', '693', '420', '633', '1044', '1043', '322', '574', '573', '199', '401', '130', '608', '590', '945', '1014', '612', '928', '539', '268', '796', '782', '317', '963', '1061', '139', '128', '75', '737', '85', '341', '365', '824', '696', '137', '983', '670', '57', '976', '998', '344', '48', '908', '369', '957', '715', '926', '1020', '363', '659', '259', '951', '798', '835', '683', '822', '195', '561', '320', '295', '528', '2', '502', '298', '477', '944', '546', '325', '565', '1039', '63', '850', '1022', '977', '635', '21', '362', '860', '151', '229', '107', '992', '1019', '702', '222', '374', '699', '623', '5', '164', '30', '174', '718', '764', '61', '778', '1032', '812', '959', '328', '6', '488', '769', '452', '830', '391', '305', '743', '108', '117', '261', '226', '402', '930', '447', '72', '100', '457', '755', '595', '622', '762', '321', '681', '719', '655', '179', '887', '995', '297', '110', '39', '828', '843', '415', '724', '113', '220', '78', '319', '814', '1012', '582', '215', '311', '238', '813', '143', '752', '1055', '403', '436', '171', '638', '986', '197', '304', '429', '122', '428', '1065', '703', '644', '628', '960', '444', '94', '579', '478', '588', '157', '416', '566', '245', '591', '708', '975', '248', '946', '273', '144', '874', '753', '564', '67', '262', '686', '360', '266', '1002', '95', '92', '889', '972', '33', '476', '562', '620', '497', '232', '587', '660', '303', '459', '629', '988', '73', '324', '569', '669', '278', '185', '1001', '134', '940', '104', '979', '750', '56', '739', '99', '783', '43', '892', '763', '102', '550', '290', '348', '676', '154', '679', '713', '643', '406', '213', '90', '443', '383', '400', '1000', '225', '84', '592', '176', '16', '768', '525', '1060', '518', '349', '326', '795', '291', '103', '747', '862', '189', '456', '249', '738', '177', '315', '646', '282', '161', '514', '382', '500', '800', '602', '909', '58', '512', '399', '858', '1016', '495', '572', '81', '730', '685', '593', '1049', '581', '875', '242', '460', '526', '52', '625', '260', '306', '390', '1047', '950', '1004', '894', '1023', '410', '932', '453', '626', '770', '407', '22', '780', '243', '864', '1013', '903', '484', '507', '1066', '847', '589', '939', '577', '722', '353', '368', '721', '378', '302', '414', '82', '385', '27', '28', '178', '869', '706', '308', '254', '209', '855', '791', '221', '665', '1064', '492', '173', '187', '210', '384', '425', '861', '283', '392', '1008', '380', '127', '827', '978', '789', '126', '12', '80', '470', '728', '310', '1011', '520', '859', '1070', '462', '330', '18', '714', '366', '922', '418', '772', '153', '784', '842', '405', '190', '54', '212', '198', '817', '496', '901', '761', '286', '895', '338', '815', '641', '920', '1028', '141', '797', '480', '435', '806', '1035', '873', '621', '120', '559', '700', '833', '1051', '742', '556', '1057', '1068', '645', '46', '1062', '868', '184', '454', '781', '123', '984', '853', '840', '138', '442', '440', '170', '293', '208', '731', '594', '642', '698', '543', '114', '617', '941', '50', '914', '251', '616', '472', '788', '53', '267', '852', '766', '560', '759', '872', '214', '236', '211', '434', '371', '555', '158', '517', '1040', '257', '194', '689', '379', '41', '744', '397', '1034', '292', '274', '680', '88', '463', '982', '662', '375', '687', '571', '958', '309', '105', '745', '148', '203', '666', '971', '1054', '93', '961', '746', '598', '899', '883', '150', '805', '230', '169', '570', '224', '312', '370', '372', '996', '877', '276', '619', '558', '165', '417', '694', '446', '776', '337', '469', '511', '1009', '354', '219', '109', '654', '316', '1038', '1052', '491', '657', '346', '786', '60', '856', '1005', '423', '651', '498', '482', '258', '749', '688', '358', '652', '1045', '393', '904', '437', '865', '331', '529', '668', '771', '802', '964', '987', '294', '307', '854', '557', '361', '196', '475', '155', '451', '68', '96', '902', '277', '448', '900', '106', '340', '981', '11', '584', '364', '848', '281', '65', '905', '804']\n",
      "Number of Relevance Features:  752\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.93      0.96        14\n",
      "     Clase 1       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.96        28\n",
      "   macro avg       0.97      0.96      0.96        28\n",
      "weighted avg       0.97      0.96      0.96        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest_classifier_with_kfcv(dataset, relevance_indices, num_folds, output_file):\n",
    "    # Assuming the last column contains the class labels\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]\n",
    "\n",
    "    # Initialize Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "    # Initialize k-Fold Cross-Validation\n",
    "    kf = KFold(n_splits = num_folds, shuffle = True, random_state = seed_new)\n",
    "\n",
    "    # Results dictionary to store metrics for each iteration\n",
    "    results = {'Accuracy': [], 'Relevance_Indices': []}\n",
    "    # Initialize an empty list to accumulate indices\n",
    "    accumulated_indices = []\n",
    "    \n",
    "    # Initialize variables to keep track of the best accuracy and its corresponding indices\n",
    "    best_accuracy = 0.0\n",
    "    best_relevance_indices = None\n",
    "    best_classification_report = None\n",
    "\n",
    "    # Iterate through relevance indices\n",
    "    for feature_index in relevance_indices:\n",
    "        # Initialize lists to store metrics for each fold\n",
    "        accuracy_list = []\n",
    "\n",
    "        # Lists to store the predicted and actual labels\n",
    "        predicted_labels = []\n",
    "        actual_labels = []\n",
    "\n",
    "        # Iterate through each fold\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Add one feature at a time based on relevance indices\n",
    "            X_train_current = X_train.iloc[:, : int(feature_index) + 1]\n",
    "            X_test_current = X_test.iloc[:, : int(feature_index) + 1]\n",
    "            \n",
    "            # Fit Random Forest classifier\n",
    "            rf_classifier.fit(X_train_current, y_train)\n",
    "            # Predict on test set\n",
    "            y_pred = rf_classifier.predict(X_test_current)\n",
    "            predicted_labels.extend(y_pred)\n",
    "            actual_labels.extend(y_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # Append accuracy to the list\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        # Calculate mean accuracy\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "        # Append mean accuracy and accumulated relevance indices for each feature to results dictionary\n",
    "        results['Accuracy'].append(mean_accuracy)\n",
    "        accumulated_indices.append(feature_index)\n",
    "        results['Relevance_Indices'].append(accumulated_indices.copy())\n",
    "\n",
    "        # Update the best accuracy and its corresponding indices\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_relevance_indices = accumulated_indices.copy()\n",
    "\n",
    "            # Calculate the best classification report\n",
    "            labels = ['Clase 0', 'Clase 1']\n",
    "            best_classification_report = classification_report(actual_labels, predicted_labels, target_names=labels)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    results['Accuracy'] = np.array(results['Accuracy'])\n",
    "    results['Relevance_Indices'] = np.array(results['Relevance_Indices'], dtype=object)\n",
    "\n",
    "    # Sort the accuracies and their corresponding indices in ascending order\n",
    "    sorted_indices = np.argsort(results['Accuracy'])\n",
    "    results['Accuracy'] = results['Accuracy'][sorted_indices]\n",
    "    results['Relevance_Indices'] = results['Relevance_Indices'][sorted_indices]\n",
    "\n",
    "    # Print the best accuracy and its corresponding indices\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Corresponding Relevance Indices: {best_relevance_indices}\")\n",
    "    print(\"Number of Relevance Features: \", len(best_relevance_indices))\n",
    "    \n",
    "    # Print the best classification report\n",
    "    print(\"Best Classification Report:\")\n",
    "    print(best_classification_report)\n",
    "\n",
    "    # Save the best classification report to a file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Best Classification Report:\\n\")\n",
    "        file.write(best_classification_report)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run SVM classifier with kFCV\n",
    "results = random_forest_classifier_with_kfcv(dataset, relevance_indices, num_folds = 10, output_file = 'best_classification_report_rf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7908c5a-5dee-403c-b8ed-1c9c7fed2b45",
   "metadata": {},
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2cee71-eef8-4a16-9969-6522fc2659da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8333333333333333\n",
      "Corresponding Relevance Indices: ['116', '142', '31', '132', '1048', '734', '695', '837', '125', '70', '867', '240', '563', '147', '323', '479', '968', '124', '505', '334', '966', '773', '777', '191', '146', '916', '227', '471', '765', '735', '609', '503', '98', '757', '118', '504', '969', '825', '336', '223', '183', '509', '980', '351', '936', '673']\n",
      "Number of Relevance Features:  46\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.85      0.79      0.81        14\n",
      "     Clase 1       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.82      0.82      0.82        28\n",
      "weighted avg       0.82      0.82      0.82        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def adaboost_classifier_with_kfcv(dataset, relevance_indices, num_folds, output_file):\n",
    "    # Assuming the last column contains the class labels\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]\n",
    "\n",
    "    # Initialize AdaBoost classifier\n",
    "    adaboost_classifier = AdaBoostClassifier(n_estimators = 50, random_state = seed_new)\n",
    "\n",
    "    # Initialize k-Fold Cross-Validation\n",
    "    kf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "\n",
    "    # Results dictionary to store metrics for each iteration\n",
    "    results = {'Accuracy': [], 'Relevance_Indices': []}\n",
    "    # Initialize an empty list to accumulate indices\n",
    "    accumulated_indices = []\n",
    "    \n",
    "    # Initialize variables to keep track of the best accuracy and its corresponding indices\n",
    "    best_accuracy = 0.0\n",
    "    best_relevance_indices = None\n",
    "    best_classification_report = None\n",
    "\n",
    "    # Iterate through relevance indices\n",
    "    for feature_index in relevance_indices:\n",
    "        # Initialize lists to store metrics for each fold\n",
    "        accuracy_list = []\n",
    "\n",
    "        # Lists to store the predicted and actual labels\n",
    "        predicted_labels = []\n",
    "        actual_labels = []\n",
    "\n",
    "        # Iterate through each fold\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Add one feature at a time based on relevance indices\n",
    "            X_train_current = X_train.iloc[:, : int(feature_index) + 1]\n",
    "            X_test_current = X_test.iloc[:, : int(feature_index) + 1]\n",
    "\n",
    "            # Fit AdaBoost classifier\n",
    "            adaboost_classifier.fit(X_train_current, y_train)\n",
    "            # Predict on test set\n",
    "            y_pred = adaboost_classifier.predict(X_test_current)\n",
    "            predicted_labels.extend(y_pred)\n",
    "            actual_labels.extend(y_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # Append accuracy to the list\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        # Calculate mean accuracy\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "        # Append mean accuracy and accumulated relevance indices for each feature to results dictionary\n",
    "        results['Accuracy'].append(mean_accuracy)\n",
    "        accumulated_indices.append(feature_index)\n",
    "        results['Relevance_Indices'].append(accumulated_indices.copy())\n",
    "\n",
    "        # Update the best accuracy and its corresponding indices\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_relevance_indices = accumulated_indices.copy()\n",
    "\n",
    "            # Calculate the best classification report\n",
    "            labels = ['Clase 0', 'Clase 1']\n",
    "            best_classification_report = classification_report(actual_labels, predicted_labels, target_names=labels)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    results['Accuracy'] = np.array(results['Accuracy'])\n",
    "    results['Relevance_Indices'] = np.array(results['Relevance_Indices'], dtype=object)\n",
    "\n",
    "    # Sort the accuracies and their corresponding indices in ascending order\n",
    "    sorted_indices = np.argsort(results['Accuracy'])\n",
    "    results['Accuracy'] = results['Accuracy'][sorted_indices]\n",
    "    results['Relevance_Indices'] = results['Relevance_Indices'][sorted_indices]\n",
    "\n",
    "    # Print the best accuracy and its corresponding indices\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Corresponding Relevance Indices: {best_relevance_indices}\")\n",
    "    print(\"Number of Relevance Features: \", len(best_relevance_indices))\n",
    "    \n",
    "    # Print the best classification report\n",
    "    print(\"Best Classification Report:\")\n",
    "    print(best_classification_report)\n",
    "\n",
    "    # Save the best classification report to a file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Best Classification Report:\\n\")\n",
    "        file.write(best_classification_report)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run MLP classifier with kFCV\n",
    "results = adaboost_classifier_with_kfcv(dataset, relevance_indices, num_folds = 10, output_file = 'best_classification_report_adaboost.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81734d-3758-44d7-9bc3-8da6b5643040",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48a39da-02bc-4da2-89d0-9e2dc060b593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7666666666666666\n",
      "Corresponding Relevance Indices: ['116', '142', '31', '132', '1048', '734', '695', '837', '125', '70', '867', '240', '563', '147', '323', '479', '968', '124', '505', '334', '966', '773', '777', '191', '146', '916', '227', '471', '765', '735', '609', '503', '98', '757', '118', '504', '969', '825', '336', '223', '183', '509', '980', '351', '936', '673', '544', '467', '422', '664', '1010', '829', '545', '115', '35', '705', '912', '270', '758', '547', '709', '748', '1', '586', '508', '1030', '610', '808', '8', '1003', '264', '538', '583', '533', '300', '863', '974', '247', '929', '458', '287', '760', '917', '76', '970', '790', '913', '216', '445', '921', '779', '726', '314', '740', '820', '636', '712', '350', '66', '356', '600', '129', '4', '1063', '535', '697', '301', '156', '906', '510', '501', '202', '792', '891', '603', '439', '74', '332', '631', '180', '1037', '396', '878', '10', '160', '490', '985', '597', '395', '536', '228', '596', '710', '1056', '34', '121', '474', '244', '531', '821', '997', '720', '918', '55', '119', '585', '774', '162', '271', '1027', '810', '464', '653', '431', '486', '967', '493', '318', '942', '534', '200', '218', '64', '284', '241', '79', '934', '756', '296', '377', '285', '819', '656', '607', '973', '884', '541', '489', '186', '548', '693', '420', '633', '1044', '1043', '322', '574', '573', '199', '401', '130', '608', '590', '945', '1014', '612', '928', '539', '268', '796', '782', '317', '963', '1061', '139', '128', '75', '737', '85', '341', '365', '824', '696', '137', '983', '670', '57', '976', '998', '344', '48', '908', '369', '957', '715', '926', '1020', '363', '659', '259', '951', '798', '835', '683', '822', '195', '561', '320', '295', '528', '2', '502', '298', '477', '944', '546', '325', '565', '1039', '63', '850', '1022', '977', '635', '21', '362', '860', '151', '229', '107', '992', '1019', '702', '222', '374', '699', '623', '5', '164', '30', '174', '718', '764', '61', '778', '1032', '812', '959', '328', '6', '488', '769', '452', '830', '391', '305', '743', '108', '117', '261', '226', '402', '930', '447', '72', '100', '457', '755', '595', '622', '762', '321', '681', '719', '655', '179', '887', '995', '297', '110', '39', '828', '843', '415', '724', '113', '220', '78', '319', '814', '1012', '582', '215', '311', '238', '813', '143', '752', '1055', '403', '436', '171', '638', '986', '197', '304', '429', '122', '428', '1065', '703', '644', '628', '960', '444', '94', '579', '478', '588', '157', '416', '566', '245', '591', '708', '975', '248', '946', '273', '144', '874', '753', '564', '67', '262', '686', '360', '266', '1002', '95', '92', '889', '972', '33', '476', '562', '620', '497', '232', '587', '660', '303', '459', '629', '988', '73', '324', '569', '669', '278', '185', '1001', '134', '940', '104', '979', '750', '56', '739', '99', '783', '43', '892', '763', '102', '550', '290', '348', '676', '154', '679', '713', '643', '406', '213', '90', '443', '383', '400', '1000', '225', '84', '592', '176', '16', '768', '525', '1060', '518', '349', '326', '795', '291', '103', '747', '862', '189', '456', '249', '738', '177', '315', '646', '282', '161', '514', '382', '500', '800', '602', '909', '58', '512', '399', '858', '1016', '495', '572', '81', '730', '685', '593', '1049', '581', '875', '242', '460', '526', '52', '625', '260', '306', '390', '1047', '950', '1004', '894', '1023', '410', '932', '453', '626', '770', '407', '22', '780', '243', '864', '1013', '903', '484', '507', '1066', '847', '589', '939', '577', '722', '353', '368', '721', '378', '302', '414', '82', '385', '27', '28', '178', '869', '706', '308', '254', '209', '855', '791', '221', '665', '1064', '492', '173', '187', '210', '384', '425', '861', '283', '392', '1008', '380', '127', '827', '978', '789', '126', '12', '80', '470', '728', '310', '1011', '520', '859', '1070', '462', '330', '18', '714', '366', '922', '418', '772', '153', '784', '842', '405', '190', '54', '212', '198', '817', '496', '901', '761', '286', '895', '338', '815', '641', '920', '1028', '141', '797', '480', '435', '806', '1035', '873', '621', '120', '559', '700', '833', '1051', '742', '556', '1057', '1068', '645', '46', '1062', '868', '184', '454', '781', '123', '984', '853', '840', '138', '442', '440', '170', '293', '208', '731', '594', '642', '698', '543', '114', '617', '941', '50', '914', '251', '616', '472', '788', '53', '267', '852', '766', '560', '759', '872', '214', '236', '211', '434', '371', '555', '158', '517', '1040', '257', '194', '689', '379', '41', '744', '397', '1034', '292', '274', '680', '88', '463', '982', '662', '375', '687', '571', '958', '309', '105', '745', '148', '203', '666', '971', '1054', '93', '961', '746', '598', '899', '883', '150', '805', '230', '169', '570', '224', '312', '370', '372', '996', '877', '276', '619', '558', '165', '417', '694', '446', '776', '337', '469', '511', '1009', '354', '219', '109', '654', '316', '1038', '1052', '491', '657', '346', '786', '60', '856', '1005', '423', '651', '498', '482', '258', '749', '688', '358', '652', '1045', '393', '904', '437', '865', '331', '529', '668', '771', '802', '964', '987', '294', '307', '854', '557', '361', '196', '475', '155', '451', '68', '96', '902', '277', '448', '900', '106', '340', '981', '11', '584', '364', '848', '281', '65', '905', '804', '605', '844', '205', '359', '672', '568', '172', '841', '51', '1018', '682', '601', '233', '767', '999', '911', '542', '357', '473', '133', '931', '36', '506', '97', '876', '347', '866', '915', '729', '775', '24', '404', '398', '343', '26', '953', '919', '1006', '345', '794', '513', '639', '690', '836', '632', '71', '299', '751', '838', '551', '412', '217', '280', '540', '532', '256', '387', '352', '898', '289', '42', '465', '886', '152', '927', '333', '962', '246', '663', '426', '263', '989', '809', '674', '272', '991', '831', '388', '207', '1033', '252', '62', '811', '101', '667', '793', '1029', '965', '521', '650', '684', '181', '17', '816', '661', '421', '255', '938', '394', '7', '192', '618', '38', '711', '893', '993', '159', '648', '870', '279', '727', '20', '624', '386', '956', '23', '524', '188', '897', '845', '732', '140', '9', '381', '549', '136', '537', '1041', '1046', '933', '265', '723', '32', '707', '40', '449', '691', '787', '692', '433', '1053', '846', '599', '59', '253', '949', '234', '818', '801', '45', '896', '803', '86', '658', '239', '335', '77', '678', '339', '637', '649', '408', '952', '924', '948', '313', '515', '910', '826', '675', '327', '269', '235', '994', '168', '553', '373', '807', '716', '499', '167', '606', '615', '15', '552', '89', '342', '640', '834', '25', '204', '163', '880', '580', '671', '851', '1031', '135', '131', '647', '885', '275', '832', '925', '468', '1021', '3', '376', '367', '879', '69', '149', '111', '935', '849', '627', '182', '461', '438', '355', '634', '441', '1026', '578', '14', '530', '741', '516', '576', '112', '785', '1024', '947', '389', '907', '481', '288', '871', '677', '145', '49', '494', '175', '522', '87', '1058', '754', '47', '839', '1007', '1025', '1042', '427', '166', '955', '527', '13', '83', '799', '881', '201', '857', '483', '1017', '701', '29', '424', '37', '954', '193', '717', '725', '823', '432', '736', '91', '430', '413', '466', '888']\n",
      "Number of Relevance Features:  1032\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.71      0.86      0.77        14\n",
      "     Clase 1       0.82      0.64      0.72        14\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.76      0.75      0.75        28\n",
      "weighted avg       0.76      0.75      0.75        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp_classifier_with_kfcv(dataset, relevance_indices, num_folds, output_file):\n",
    "    # Assuming the last column contains the class labels\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]\n",
    "\n",
    "    # Initialize MLP classifier with 10 hidden layers\n",
    "    mlp_classifier = MLPClassifier(hidden_layer_sizes = (20,), max_iter = 1000, early_stopping = True, random_state = 42)\n",
    "\n",
    "    # Initialize k-Fold Cross-Validation\n",
    "    kf = KFold(n_splits = num_folds, shuffle = True, random_state = seed_new)\n",
    "\n",
    "    # Results dictionary to store metrics for each iteration\n",
    "    results = {'Accuracy': [], 'Relevance_Indices': []}\n",
    "    # Initialize an empty list to accumulate indices\n",
    "    accumulated_indices = []\n",
    "    \n",
    "    # Initialize variables to keep track of the best accuracy and its corresponding indices\n",
    "    best_accuracy = 0.0\n",
    "    best_relevance_indices = None\n",
    "    best_classification_report = None\n",
    "\n",
    "   # Iterate through relevance indices\n",
    "    for feature_index in relevance_indices:\n",
    "        # Initialize lists to store metrics for each fold\n",
    "        accuracy_list = []\n",
    "\n",
    "        # Lists to store the predicted and actual labels\n",
    "        predicted_labels = []\n",
    "        actual_labels = []\n",
    "\n",
    "        # Iterate through each fold\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Add one feature at a time based on relevance indices\n",
    "            X_train_current = X_train.iloc[:, : int(feature_index) + 1]\n",
    "            X_test_current = X_test.iloc[:, : int(feature_index) + 1]\n",
    "\n",
    "            # Fit MLP classifier\n",
    "            mlp_classifier.fit(X_train_current, y_train)\n",
    "            # Predict on test set\n",
    "            y_pred = mlp_classifier.predict(X_test_current)\n",
    "            predicted_labels.extend(y_pred)\n",
    "            actual_labels.extend(y_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # Append accuracy to the list\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        # Calculate mean accuracy\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "        # Append mean accuracy and accumulated relevance indices for each feature to results dictionary\n",
    "        results['Accuracy'].append(mean_accuracy)\n",
    "        accumulated_indices.append(feature_index)\n",
    "        results['Relevance_Indices'].append(accumulated_indices.copy())\n",
    "\n",
    "        # Update the best accuracy and its corresponding indices\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_relevance_indices = accumulated_indices.copy()\n",
    "\n",
    "            # Calculate the best classification report\n",
    "            labels = ['Clase 0', 'Clase 1']\n",
    "            best_classification_report = classification_report(actual_labels, predicted_labels, target_names = labels)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    results['Accuracy'] = np.array(results['Accuracy'])\n",
    "    results['Relevance_Indices'] = np.array(results['Relevance_Indices'], dtype=object)\n",
    "\n",
    "    # Sort the accuracies and their corresponding indices in ascending order\n",
    "    sorted_indices = np.argsort(results['Accuracy'])\n",
    "    results['Accuracy'] = results['Accuracy'][sorted_indices]\n",
    "    results['Relevance_Indices'] = results['Relevance_Indices'][sorted_indices]\n",
    "\n",
    "    # Print the best accuracy and its corresponding indices\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Corresponding Relevance Indices: {best_relevance_indices}\")\n",
    "    print(\"Number of Relevance Features: \", len(best_relevance_indices))\n",
    "    \n",
    "    # Print the best classification report\n",
    "    print(\"Best Classification Report:\")\n",
    "    print(best_classification_report)\n",
    "\n",
    "    # Save the best classification report to a file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Best Classification Report:\\n\")\n",
    "        file.write(best_classification_report)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run MLP classifier with kFCV\n",
    "results = mlp_classifier_with_kfcv(dataset, relevance_indices, num_folds = 10, output_file = 'best_classification_report_mlp.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc7d99-8d28-44e3-8a1e-b4cb9f432463",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d112a5-f0a9-44d2-9037-7b09b9dfa995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8333333333333333\n",
      "Corresponding Relevance Indices: ['116', '142', '31', '132', '1048', '734', '695', '837', '125', '70', '867', '240', '563', '147', '323', '479', '968', '124', '505', '334', '966', '773', '777', '191', '146', '916', '227', '471', '765', '735', '609', '503', '98', '757', '118', '504', '969', '825', '336', '223', '183', '509', '980', '351', '936', '673', '544', '467', '422']\n",
      "Number of Relevance Features:  49\n",
      "Best Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.74      1.00      0.85        14\n",
      "     Clase 1       1.00      0.64      0.78        14\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.87      0.82      0.82        28\n",
      "weighted avg       0.87      0.82      0.82        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def naive_bayes_classifier_with_kfcv(dataset, relevance_indices, num_folds, output_file):\n",
    "    # Assuming the last column contains the class labels\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]\n",
    "\n",
    "    # Initialize Gaussian Naive Bayes classifier\n",
    "    nb_classifier = GaussianNB()\n",
    "\n",
    "    # Initialize k-Fold Cross-Validation\n",
    "    kf = KFold(n_splits = num_folds, shuffle = True, random_state = seed_new)\n",
    "\n",
    "    # Results dictionary to store metrics for each iteration\n",
    "    results = {'Accuracy': [], 'Relevance_Indices': []}\n",
    "    # Initialize an empty list to accumulate indices\n",
    "    accumulated_indices = []\n",
    "    \n",
    "    # Initialize variables to keep track of the best accuracy and its corresponding indices\n",
    "    best_accuracy = 0.0\n",
    "    best_relevance_indices = None\n",
    "    best_classification_report = None\n",
    "\n",
    "    # Iterate through relevance indices\n",
    "    for feature_index in relevance_indices:\n",
    "        # Initialize lists to store metrics for each fold\n",
    "        accuracy_list = []\n",
    "\n",
    "        # Lists to store the predicted and actual labels\n",
    "        predicted_labels = []\n",
    "        actual_labels = []\n",
    "\n",
    "        # Iterate through each fold\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Add one feature at a time based on relevance indices\n",
    "            X_train_current = X_train.iloc[:, : int(feature_index) + 1]\n",
    "            X_test_current = X_test.iloc[:, : int(feature_index) + 1]\n",
    "\n",
    "            # Fit Gaussian Naive Bayes classifier\n",
    "            nb_classifier.fit(X_train_current, y_train)\n",
    "\n",
    "            # Predict on test set\n",
    "            X_test_current = X_test.iloc[:, :int(feature_index) + 1]\n",
    "            y_pred = nb_classifier.predict(X_test_current)\n",
    "\n",
    "            predicted_labels.extend(y_pred)\n",
    "            actual_labels.extend(y_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # Append accuracy to the list\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        # Calculate mean accuracy\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "\n",
    "        # Append mean accuracy and accumulated relevance indices for each feature to results dictionary\n",
    "        results['Accuracy'].append(mean_accuracy)\n",
    "        accumulated_indices.append(feature_index)\n",
    "        results['Relevance_Indices'].append(accumulated_indices.copy())\n",
    "\n",
    "        # Update the best accuracy and its corresponding indices\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_relevance_indices = accumulated_indices.copy()\n",
    "\n",
    "            # Calculate the best classification report\n",
    "            labels = ['Clase 0', 'Clase 1']\n",
    "            best_classification_report = classification_report(actual_labels, predicted_labels, target_names = labels)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    results['Accuracy'] = np.array(results['Accuracy'])\n",
    "    results['Relevance_Indices'] = np.array(results['Relevance_Indices'], dtype=object)\n",
    "\n",
    "    # Sort the accuracies and their corresponding indices in ascending order\n",
    "    sorted_indices = np.argsort(results['Accuracy'])\n",
    "    results['Accuracy'] = results['Accuracy'][sorted_indices]\n",
    "    results['Relevance_Indices'] = results['Relevance_Indices'][sorted_indices]\n",
    "\n",
    "    # Print the best accuracy and its corresponding indices\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Corresponding Relevance Indices: {best_relevance_indices}\")\n",
    "    print(\"Number of Relevance Features: \", len(best_relevance_indices))\n",
    "    \n",
    "    # Print the best classification report\n",
    "    print(\"Best Classification Report:\")\n",
    "    print(best_classification_report)\n",
    "\n",
    "    # Save the best classification report to a file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Best Classification Report:\\n\")\n",
    "        file.write(best_classification_report)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run NB classifier with kFCV\n",
    "results = naive_bayes_classifier_with_kfcv(dataset, relevance_indices, num_folds = 10, output_file = 'best_classification_report_nb.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
